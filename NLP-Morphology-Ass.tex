
\documentclass[11pt]{article}
%\usepackage[top=20mm,left=20mm,right=20mm,bottom=15mm,a4paper]{geometry} % see geometry.pdf on how to lay out the page. There's lots.
\usepackage[top=20mm,left=20mm,right=20mm,bottom=15mm,headsep=15pt,footskip=15pt,a4paper]{geometry} % see geometry.pdf on how to lay out the page. There's lots.
%\geometry{a4paper} % or letter or a5paper or ... etc
% \geometry{landscape} % rotated page geometry
\usepackage[round]{natbib}
\setlength{\bibsep}{0.0pt}
\usepackage{color}
\usepackage{times}
%\usepackage[T1]{fontenc}
%\usepackage{mathptmx}
\usepackage{tikz-dependency}
\usepackage{enumitem}
%\usepackage{times}

\usepackage[procnames]{listings}
\usepackage{color}
 
 

% See the ``Article customise'' template for come common customisations
\newcommand{\refeq}[1]{Equation~\ref{eq:#1}}
\newcommand{\reffig}[1]{Figure~\ref{fig:#1}}
\newcommand{\reftab}[1]{Table~\ref{tab:#1}}
\newcommand{\refsec}[1]{\textsection\ref{sec:#1}}
\newcommand{\newsec}[2]{\section{#1}\label{sec:#2}\noindent}
\newcommand{\newsubsec}[2]{\subsection{#1}\label{sec:#2}\noindent}
\newcommand{\argmax}{\operatornamewithlimits{argmax}} 
\newcommand{\argmin}{\operatornamewithlimits{argmin}} 

\makeatletter         
\def\@maketitle{   % custom maketitle 
\begin{center}%
{\bfseries \@title}%
{\bfseries \@author}%
\end{center}%
\smallskip \hrule \bigskip }

% custom section 
\renewcommand{\section}{\@startsection
{section}%                   % the name
{1}%                         % the level
{0mm}%                       % the indent
{-0.8\baselineskip}%            % the before skip
{0.3\baselineskip}%          % the after skip
{\bfseries\large}}% the style

% custom subsection 
\renewcommand{\subsection}{\@startsection
{subsection}%                   % the name
{2}%                         % the level
{0mm}%                       % the indent
{-0.8\baselineskip}%            % the before skip
{0.3\baselineskip}%          % the after skip
{\bfseries\large}}% the style

\renewcommand{\paragraph}{%
  \@startsection{paragraph}{4}%
  {\z@}{1.5ex \@plus 1ex \@minus .2ex}{-1em}%
  {\normalfont\normalsize\bfseries}%
}\makeatother

%\title{{\LARGE Universal Parser (UP)}\\[-8mm]
%\includegraphics[height=8mm]{RUPA}~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\includegraphics[height=8mm]{RUPA}}
\title{{\LARGE Natural Language Processing}\\[1.5mm]{\large Assignment 7: Lemmatization}}
\author{}
\date{} % delete this line to display the current date

%%% BEGIN DOCUMENT
\begin{document}

\definecolor{keywords}{RGB}{255,0,90}
\definecolor{comments}{RGB}{0,0,113}
\definecolor{red}{RGB}{160,0,0}
\definecolor{green}{RGB}{0,150,0}
 
\lstset{language=Python, 
        basicstyle=\ttfamily\small, 
        keywordstyle=\color{keywords},
        commentstyle=\color{comments},
        stringstyle=\color{red},
        showstringspaces=false,
        identifierstyle=\color{green},
        procnamekeys={def,class}}

\maketitle
%\tableofcontents
%\vspace{3mm}
\vspace{-2mm} \newsec{Introduction}{intro}%
Full morphological analysis and lemmatization normally presupposes a
comprehensive lexicon. In this assignment, we will investigate a
lexicon-free method for lemmatization of English based on rule-based
stemming techniques.

\newsec{Data}{data}%
We are going to make use of the same data from the English Web
Treebank that we used in the tagging assignment. However, since we are
using an approach based on hand-crafted rules, we just need a
development set and not a separate training set. As input to the
lemmatizer, we will use the file {\tt ewt-dev-wt.txt}, which contains
both words and part-of-speech tags, and the task is to predict the
base form of the word. The gold standard is provided in the file {\tt
  ewt-dev-wtl.txt}, which contains words, tags and lemmas.  All the
files needed can be found in {\tt /local/kurs/nlp/tagging/}.

\newsec{Starter code}{code}%
The file {\tt lemmatizer.py} contains skeleton code for a rule-based lemmatizer:
\begin{center}
\fbox{
\lstinputlisting{code/lemmatizer1.py}
}
\end{center}
The main program reads the input file line by line and adds a lemma
after the word and tag. It uses three simple methods for lemmatization
of nouns, verbs and adjectives and otherwise treats the token as its
own lemma. The program is run as follows:
\begin{verbatim}
python3 lemmatizer.py < ewt-dev-wt.txt > ewt-dev-out.txt
\end{verbatim}
To evaluate the quality of the lemmatization, you can use {\tt score.py} with the flag {\tt lemma}:
\begin{verbatim}
python3 score.py lemma ewt-dev-wtl.txt ewt-dev-out.txt
\end{verbatim}

\newsec{Improve lemmatization (10 P)}{improve}%
The simple baseline lemmatizer has an accuracy of 80\%. Your task is
to improve the accuracy as much as possible by modifying the code. You
may expand existing methods,
add new methods, or modify the main program, as you see fit. To get inspiration, you can consult the sections on stemming in the textbook. To find out which words your lemmatizer still gets wrong, you may use the \texttt{diff} command on the command line:\\

\noindent
\texttt{diff ewt-dev-wtl.txt ewt-dev-out.txt | less}\\

\noindent
The goal is to reach at least 85\% accuracy on the development set.

\newsec{Error analysis (5 P)}{error}%
When you are satisfied with the accuracy of your lemmatizer, you
should do a manual analysis of remaining errors. Describe at least 5
error types and discuss how they could be tackled in a more
sophisticated lemmatizer.

\newsec{Illustrate an FST (5 P)} %
LLemmatizers are often implemented as finite-state-transducers
(FSTs). While this kind of implementation is beyond the scope of this
course, Chapter 3.5 (FSTs for Morphological Parsing) of our course
book gives examples of how FSTs can be visualised. Draw an FST based
on the initial lemmatizer we gave you on the previous page that can
analyse the following words: \texttt{cats NOUN}, \texttt{jumped VERB},
\texttt{higher ADJ}. You can either draw the FST 1) by hand, take a
picture, transform it to \texttt{.pdf}, or 2) using a drawing program
(e.g. xfig or MS Paint) and transform the output into \texttt{.pdf}.

\newsec{Submit the assignment}{submit}%
Upload the following to {\it Studentportalen}, \textbf{before 20:00h
  December 2nd}. In order to pass you must provide answers to all
exercises and achieve at least 15/20 points.
\begin{itemize}[noitemsep,topsep=0.2cm]
\item Code for a lemmatizer that achieves at least 85\% accuracy on
  the development set\\ (Section 4, \texttt{firstname.py\footnote{Please
      substitute \emph{firstname} by your first name (and only your
      first name), e.g. \texttt{fabienne.py}}} format).
\item The output-file this lemmatizer produces\\(Section 4,
  \texttt{firstname\_output.txt}).
\item The ouput of the scoring script for this lemmatizer\\ (Section 4,
  \texttt{firstname\_scoring.txt}).
\item A discussion of at least 5 remaining error types\\ (Section 5,
  ca. 1/2 page, \texttt{firstname\_discussion.pdf} written in
  \LaTeX).
\item A drawing of how the FST corresponding to the initial lemmatizer
  we gave you would look like\\ (Section 6,
  \texttt{firstname\_drawing.pdf})
\item \textbf{[VG]} In order to get the grade VG, reach at least 18
  points in the exercises above and submit a lemmatizer with at least
  95\% accurracy. 
\end{itemize}

\end{document}